Optimal batch size: https://dmitry.ai/t/topic/100/2

---

Overfitting: If your training loss is much lower than validation loss then this means the network might be overfitting. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.

Underfitting: If your training/validation loss are about equal then your model is underfitting. Increase the size of your model (either number of layers or the raw number of neurons per layer)

---

STFT y WINDOW:
https://towardsdatascience.com/understanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520

Librosa paper:
http://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf


---

Saarbruecken Voice Database:
http://stimmdb.coli.uni-saarland.de/index.php4#target

---
Artículos interesantes: 

What’s wrong with CNNs and spectrograms for audio processing?
https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd

Can convolution extract useful features from a spectrogram of seismic measurements?
https://www.kaggle.com/michael422/spectrogram-convolution

---

delta stack:
https://gist.github.com/stevemclaugh/80f192130852353ad53e6d8b6b275983
mffc tutorial:
http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/

what is loss? 
https://www.youtube.com/watch?v=Skc8nqJirJg